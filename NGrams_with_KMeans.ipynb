{"cells":[{"cell_type":"code","execution_count":57,"id":"3d63dad0","metadata":{"id":"3d63dad0","executionInfo":{"status":"ok","timestamp":1708376395128,"user_tz":0,"elapsed":829,"user":{"displayName":"Anthony Owen","userId":"00483889762394840729"}}},"outputs":[],"source":["#some notes\n","#1. Doesn't look like a player receive a curse is treated as an action\n","#2. Should I add round end markers?\n","#3. Does normalising the ngram probabilities with the number of events in the trace make sense?\n","#4. Why does a medium skill MCTS agent buy a curse card?"]},{"cell_type":"code","execution_count":58,"id":"d792f3be","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d792f3be","executionInfo":{"status":"ok","timestamp":1708376398828,"user_tz":0,"elapsed":2888,"user":{"displayName":"Anthony Owen","userId":"00483889762394840729"}},"outputId":"c82bb42f-98ee-457c-caf4-7513bfd4d96f"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["import pandas as pd\n","import pdb\n","import re\n","import nltk\n","import numpy as np\n","import matplotlib.cm as cm\n","import matplotlib.pyplot as plt\n","from itertools import product\n","from itertools import combinations\n","from itertools import permutations\n","from nltk import ngrams\n","from nltk.probability import FreqDist\n","nltk.download('punkt')\n","from collections import Counter\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_samples, silhouette_score\n","from scipy.spatial.distance import jensenshannon\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","\n","#define number of NGrams to use\n","N = 3"]},{"cell_type":"code","execution_count":59,"id":"dc952cf0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dc952cf0","executionInfo":{"status":"ok","timestamp":1708376398829,"user_tz":0,"elapsed":13,"user":{"displayName":"Anthony Owen","userId":"00483889762394840729"}},"outputId":"8f7bc348-e7e5-4f99-81a5-1812b8017b4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["       GameID  Player  Round  Turn              ActionDescription\n","0           2       0      0     0              End Current Phase\n","1           2       0      0     0    BuyCard: COPPER by player 0\n","2           2       1      0     1              End Current Phase\n","3           2       1      0     1     BuyCard: DUCHY by player 1\n","4           2       0      1     0              End Current Phase\n","...       ...     ...    ...   ...                            ...\n","25106     201       0     18     0     BuyCard: DUCHY by player 0\n","25107     201       1     18     1              End Current Phase\n","25108     201       1     18     1    BuyCard: SMITHY by player 1\n","25109     201       0     19     0              End Current Phase\n","25110     201       0     19     0  BuyCard: PROVINCE by player 0\n","\n","[25111 rows x 5 columns]\n","Index(['GameID', 'Player', 'Round', 'Turn', 'ActionDescription'], dtype='object')\n"]}],"source":["#data  = pd.read_csv(\"data/ActionsReduced_BMWG_vs_DW_GPM100.csv\")\n","data  = pd.read_csv(\"gdrive/My Drive/Colab Notebooks/NGrams/Data/ActionsReduced_Budget50_vs_Budget500_GPM100_FG1E.csv\")\n","data = data[['GameID', 'Player', 'Round','Turn','ActionDescription']]\n","#data  = pd.read_csv(\"data/2Player_FG1E_Supply_AllYears_ActionTraces.csv\")\n","print(data)\n","print(data.columns)"]},{"cell_type":"code","execution_count":60,"id":"56736119","metadata":{"id":"56736119","executionInfo":{"status":"ok","timestamp":1708376398829,"user_tz":0,"elapsed":11,"user":{"displayName":"Anthony Owen","userId":"00483889762394840729"}}},"outputs":[],"source":["LOGS_FROM_TAG = True\n","NoOfGames = len(data['GameID'].unique())\n","\n","#label all games with corresponding agent names\n","if LOGS_FROM_TAG == True:\n","    agents = ['MediumA', 'MediumB']\n","    games_per_matchup = 100\n","    self_play = False\n","\n","    #first generate match-ups\n","    matchups = []\n","    if self_play:\n","        for agent1 in agents:\n","            for agent2 in agents:\n","                matchups.append((agent1, agent2))\n","    else:\n","        matchups = list(permutations(agents, 2))\n","\n","    #function to map gameID to match-up\n","    def gameID_to_matchup(game_id, player_no, matchup_list, no_games_per_matchup, min_game_id):\n","        game_group = int((game_id - min_game_id)/no_games_per_matchup)\n","        matchup = matchup_list[game_group]\n","        agent1, agent2 = matchup\n","        if player_no == 0:\n","            return agent1\n","        else:\n","            return agent2\n","\n","    #add agent names to data set\n","    min_GameID = data['GameID'].min()\n","    data['AgentName'] = data.apply(lambda row: gameID_to_matchup(row['GameID'], row['Player'], matchups, games_per_matchup, min_GameID), axis = 1)"]},{"cell_type":"code","execution_count":61,"id":"a83be4da","metadata":{"id":"a83be4da","executionInfo":{"status":"ok","timestamp":1708376398830,"user_tz":0,"elapsed":12,"user":{"displayName":"Anthony Owen","userId":"00483889762394840729"}}},"outputs":[],"source":["#kingdom card types\n","card_types_SD = ['ARTISAN', 'BANDIT', 'BUREAUCRAT', 'CHAPEL', 'FESTIVAL', 'GARDENS', 'SENTRY', 'THRONE_ROOM', 'WITCH',\n","                 'WORKSHOP', 'CURSE', 'PROVINCE', 'DUCHY', 'ESTATE', 'GOLD', 'SILVER', 'COPPER']\n","card_types_SD_no_curse = ['ARTISAN', 'BANDIT', 'BUREAUCRAT', 'CHAPEL', 'FESTIVAL', 'GARDENS', 'SENTRY', 'THRONE_ROOM', 'WITCH',\n","                 'WORKSHOP','PROVINCE', 'DUCHY', 'ESTATE', 'GOLD', 'SILVER', 'COPPER']\n","card_types_FG1E = ['CELLAR','MARKET','MILITIA','MINE','MOAT','REMODEL','SMITHY','VILLAGE',\n","                'WOODCUTTER','WORKSHOP','CURSE','PROVINCE', 'DUCHY', 'ESTATE', 'GOLD', 'SILVER', 'COPPER']\n","card_types = card_types_FG1E\n","#card_types = card_types_SD_no_curse\n","#card_types = card_types_SD"]},{"cell_type":"code","execution_count":62,"id":"5772e278","metadata":{"id":"5772e278","executionInfo":{"status":"ok","timestamp":1708376398830,"user_tz":0,"elapsed":12,"user":{"displayName":"Anthony Owen","userId":"00483889762394840729"}}},"outputs":[],"source":["#first format action decription\n","def format_action(action, cardtypes):\n","    #there are various types of actions we need to format to identify these we use\n","    #regular expressions\n","    pattern1 = re.compile(r'End Current Phase')\n","    pattern2 = re.compile(r'BuyCard: (' + '|'.join(cardtypes) + r') by player (0|1)')\n","    pattern3 = re.compile(r'(' + '|'.join(cardtypes) + r') : Player (0|1)')\n","    pattern4 = re.compile(r'GainCard: (' + '|'.join(cardtypes) + r') by player (0|1)')\n","    pattern5 = re.compile(r'Player (0|1) trashes a (' + '|'.join(cardtypes) + r') from (?:HAND|DISCARD)')\n","    pattern6 = re.compile(r'DoNothing')\n","    pattern7 = re.compile(r'Player (0|1) moves (' + '|'.join(cardtypes) + r') from HAND to DRAW of player (0|1) \\(visible: (?:true|false)\\)')\n","    pattern8 = re.compile(r'Reveals Hand')\n","    pattern9 = re.compile(r'Sentry .*$') #captures playing a sentry and then discard/trash two cards\n","    pattern10 = re.compile(r'Player (0|1) discards (' + '|'.join(cardtypes) + r')')\n","    pattern11 = re.compile(r'Player (0|1) reveals a (' + '|'.join(cardtypes) + r')')\n","\n","    match1 = pattern1.match(action)\n","    match2 = None\n","    match3 = None\n","    match4 = None\n","    match5 = None\n","    match6 = None\n","    match7 = None\n","    match8 = None\n","    match9 = None\n","    match10 = None\n","    match11 = None\n","    if match1 == None:\n","        match2 = pattern2.match(action)\n","    if match2 == None:\n","        match3 = pattern3.match(action)\n","    if match3 == None:\n","        match4 = pattern4.match(action)\n","    if match4 == None:\n","        match5 = pattern5.match(action)\n","    if match5 == None:\n","        match6 = pattern6.match(action)\n","    if match6 == None:\n","        match7 = pattern7.match(action)\n","    if match7 == None:\n","        match8 = pattern8.match(action)\n","    if match8 == None:\n","        match9 = pattern9.match(action)\n","    if match9 == None:\n","        match10 = pattern10.match(action)\n","    if match10 == None:\n","        match11 = pattern11.match(action)\n","\n","    if match1 != None:\n","        formatted_action = 'ECP'\n","    elif match2 != None:\n","        matched_card = match2.group(1)\n","        formatted_action = 'BUY' + matched_card\n","    elif match3 != None:\n","        matched_card = match3.group(1)\n","        formatted_action = 'PLAY' + matched_card\n","    elif match4 != None:\n","        matched_card = match4.group(1)\n","        formatted_action = 'GAIN' + matched_card\n","    elif match5 != None:\n","        matched_card = match5.group(2)\n","        formatted_action = 'TRASHES' + matched_card\n","    elif match6 != None:\n","        formatted_action = 'DONOTHING'\n","    elif match7 != None:\n","        matched_card = match7.group(2)\n","        formatted_action = 'MOVES' + matched_card\n","    elif match8 != None:\n","        formatted_action = 'REVEALSHAND'\n","    elif match9 != None:\n","        formatted_action = 'PLAYSSENTRY'\n","    elif match10 != None:\n","        matched_card = match10.group(2)\n","        formatted_action = 'DISCARDS' + matched_card\n","    elif match11 != None:\n","        matched_card = match11.group(2)\n","        formatted_action = 'REVEALS' + matched_card\n","    else:\n","        pdb.set_trace()\n","        raise Exception(\"Can't match action description\")\n","\n","    return formatted_action\n","\n","#print(format_action('GOLD : Player 1', card_types_SD))\n","#print(format_action('BuyCard: PROVINCE by player 1', card_types))\n","#print(format_action('End Current Phase', card_types_SD))"]},{"cell_type":"code","execution_count":63,"id":"352a3f49","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"352a3f49","executionInfo":{"status":"ok","timestamp":1708376398831,"user_tz":0,"elapsed":12,"user":{"displayName":"Anthony Owen","userId":"00483889762394840729"}},"outputId":"343d7999-d48e-4d9d-8796-abeb5fb39625"},"outputs":[{"output_type":"stream","name":"stdout","text":["       GameID  Player  Round  Turn              ActionDescription AgentName  \\\n","0           2       0      0     0              End Current Phase   MediumA   \n","1           2       0      0     0    BuyCard: COPPER by player 0   MediumA   \n","2           2       1      0     1              End Current Phase   MediumB   \n","3           2       1      0     1     BuyCard: DUCHY by player 1   MediumB   \n","4           2       0      1     0              End Current Phase   MediumA   \n","...       ...     ...    ...   ...                            ...       ...   \n","25106     201       0     18     0     BuyCard: DUCHY by player 0   MediumB   \n","25107     201       1     18     1              End Current Phase   MediumA   \n","25108     201       1     18     1    BuyCard: SMITHY by player 1   MediumA   \n","25109     201       0     19     0              End Current Phase   MediumB   \n","25110     201       0     19     0  BuyCard: PROVINCE by player 0   MediumB   \n","\n","        ProcAction  \n","0              ECP  \n","1        BUYCOPPER  \n","2              ECP  \n","3         BUYDUCHY  \n","4              ECP  \n","...            ...  \n","25106     BUYDUCHY  \n","25107          ECP  \n","25108    BUYSMITHY  \n","25109          ECP  \n","25110  BUYPROVINCE  \n","\n","[25111 rows x 7 columns]\n"]}],"source":["#process input file\n","data['ProcAction'] = data.apply(lambda row: format_action(row['ActionDescription'], card_types), axis = 1)\n","print(data)"]},{"cell_type":"code","execution_count":64,"id":"53ac4842","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"53ac4842","executionInfo":{"status":"ok","timestamp":1708376398831,"user_tz":0,"elapsed":10,"user":{"displayName":"Anthony Owen","userId":"00483889762394840729"}},"outputId":"39d4f398-c7de-42bd-8c7d-173c6b7f8b39"},"outputs":[{"output_type":"stream","name":"stdout","text":["Action list length: 123\n","N-gram list length: 1860867\n"]}],"source":["#create list of all possible actions - note we are ignoring responses to opponents cards (for SD this means just\n","#ignoring receiving curse cards\n","all_actions_list = []\n","all_actions_list.append(['ECP'])\n","all_actions_list.append(['BUY' + str(card) for card in card_types])\n","all_actions_list.append(['PLAY' + str(card) for card in card_types])\n","all_actions_list.append(['GAIN' + str(card) for card in card_types])\n","all_actions_list.append(['TRASHES' + str(card) for card in card_types])\n","all_actions_list.append(['DONOTHING'])\n","all_actions_list.append(['MOVES' + str(card) for card in card_types])\n","all_actions_list.append(['REVEALSHAND'])\n","all_actions_list.append(['PLAYSSENTRY'])\n","all_actions_list.append(['DISCARDS' + str(card) for card in card_types])\n","all_actions_list.append(['REVEALS' + str(card) for card in card_types])\n","all_actions_list = [item for sublist in all_actions_list for item in sublist]\n","print(\"Action list length: \" + str(len(all_actions_list)))\n","#print(all_actions_list)\n","\n","#create list of all possible N-grams\n","all_ngrams_list = list(product(all_actions_list, repeat=N))\n","#print(all_ngrams_list)\n","print(\"N-gram list length: \" + str(len(all_ngrams_list)))"]},{"cell_type":"code","execution_count":65,"id":"ae6b11ad","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ae6b11ad","executionInfo":{"status":"ok","timestamp":1708376400186,"user_tz":0,"elapsed":1363,"user":{"displayName":"Anthony Owen","userId":"00483889762394840729"}},"outputId":"7e64e946-3b73-4683-94dd-a28eef7bc19e"},"outputs":[{"output_type":"stream","name":"stdout","text":["     GameID  Player AgentName  \\\n","0         2       0   MediumA   \n","1         2       1   MediumB   \n","2         3       0   MediumA   \n","3         3       1   MediumB   \n","4         4       0   MediumA   \n","..      ...     ...       ...   \n","395     199       1   MediumA   \n","396     200       0   MediumB   \n","397     200       1   MediumA   \n","398     201       0   MediumB   \n","399     201       1   MediumA   \n","\n","                                            ProcAction  \\\n","0    ECP BUYCOPPER ECP BUYSMITHY ECP BUYESTATE PLAY...   \n","1    ECP BUYDUCHY ECP BUYESTATE ECP BUYSILVER ECP B...   \n","2    ECP ECP ECP BUYWOODCUTTER ECP BUYESTATE PLAYWO...   \n","3    ECP BUYSILVER ECP BUYSILVER ECP BUYCOPPER ECP ...   \n","4    ECP BUYESTATE ECP BUYSMITHY PLAYSMITHY BUYSILV...   \n","..                                                 ...   \n","395  ECP BUYESTATE ECP BUYSILVER ECP BUYDUCHY ECP B...   \n","396  ECP BUYSILVER ECP BUYSILVER ECP BUYSILVER ECP ...   \n","397  ECP BUYESTATE ECP BUYSILVER ECP BUYMOAT ECP BU...   \n","398  ECP BUYSILVER ECP BUYSILVER ECP BUYDUCHY ECP B...   \n","399  ECP BUYCOPPER ECP BUYWOODCUTTER ECP BUYSILVER ...   \n","\n","                                                NGrams  \n","0    [(ECP, BUYCOPPER, ECP), (BUYCOPPER, ECP, BUYSM...  \n","1    [(ECP, BUYDUCHY, ECP), (BUYDUCHY, ECP, BUYESTA...  \n","2    [(ECP, ECP, ECP), (ECP, ECP, BUYWOODCUTTER), (...  \n","3    [(ECP, BUYSILVER, ECP), (BUYSILVER, ECP, BUYSI...  \n","4    [(ECP, BUYESTATE, ECP), (BUYESTATE, ECP, BUYSM...  \n","..                                                 ...  \n","395  [(ECP, BUYESTATE, ECP), (BUYESTATE, ECP, BUYSI...  \n","396  [(ECP, BUYSILVER, ECP), (BUYSILVER, ECP, BUYSI...  \n","397  [(ECP, BUYESTATE, ECP), (BUYESTATE, ECP, BUYSI...  \n","398  [(ECP, BUYSILVER, ECP), (BUYSILVER, ECP, BUYSI...  \n","399  [(ECP, BUYCOPPER, ECP), (BUYCOPPER, ECP, BUYWO...  \n","\n","[400 rows x 5 columns]\n"]}],"source":["#convert input data so that each row contains gameID, player and then a list of ngrams\n","#corresponding to the trace\n","traces = data.groupby(['GameID', 'Player','AgentName'])['ProcAction'].agg(lambda x: ' '.join(x)).reset_index()\n","traces['NGrams'] = traces.apply(lambda row: list(ngrams(nltk.word_tokenize(row['ProcAction']),N)), axis = 1)\n","print(traces)"]},{"cell_type":"code","execution_count":66,"id":"0b646b11","metadata":{"id":"0b646b11","executionInfo":{"status":"ok","timestamp":1708376400187,"user_tz":0,"elapsed":5,"user":{"displayName":"Anthony Owen","userId":"00483889762394840729"}}},"outputs":[],"source":["#function to compute N-gram probabilities, returns either an array with probability values\n","#in the same order as ngrams in ngrams_all, or a dictionary with the n-grams as key\n","#Unobserved ngrams (i.e. ngrams in ngrams_all, that are not in the trace) are assigned\n","#a default probability of zero.\n","def calc_probabilities(ngrams_trace, ngrams_all, convertToArray = False):\n","    # Compute the frequency of ngrams in the trace\n","    frequency_counter = Counter(ngrams_trace)\n","\n","    #calculate frequencies of all ngrams in ngrams_all that appear in the playtrace\n","    event_count = {gram: frequency_counter.get(gram, 0) for gram in ngrams_all}\n","\n","    #normalise each entry with the number of n-grams observed for that trace, to convert\n","    #counts into probabilities\n","    trace_n_gram_count = sum(frequency_counter.values())\n","    probs = {key: value / (1.0*trace_n_gram_count) for key, value in event_count.items()}\n","\n","    if convertToArray:\n","        probs = np.array(list(probs.values()))\n","\n","    return probs\n","\n","#function to take a probability dictionary and create an array\n","def prob_dict_to_array(prob_dict):\n","    return np.array(list(prob_dict.values()))\n","\n","#funciton to take probability array and convert to dictionary with n-grams as keys\n","#assumes ordering has been maintained\n","def prob_array_to_dict(prob_array, ngrams_all):\n","    prob_dict = {}\n","    index = 0\n","    for gram in ngrams_all:\n","        prob_dict[gram] = prob_array[index]\n","        index+=1\n","    return prob_dict\n","\n","#find the common set of ngrams between two probability dictionaries, with probabilities\n","#above a given threshold\n","def return_common_ngrams_above_threshold(prob_dict1, prob_dict2, threshold):\n","    common_ngrams = []\n","    #look for entries in the first dictionary with non-zero values\n","    for key, value in prob_dict1.items():\n","        if value > threshold:\n","            common_ngrams.append(key)\n","    #repeat for the second dictionary but avoiding duplicates\n","    for key, value in prob_dict2.items():\n","        if (value > threshold) and (key not in common_ngrams):\n","             common_ngrams.append(key)\n","    return common_ngrams\n","\n","#convert a list of ngram tuples into a list of strings\n","def convert_ngram_tuples_to_strings(ngrams_list):\n","    ngrams_str = []\n","    for tuple_item in ngrams_list:\n","        tuple_str = ''\n","        for index, element in enumerate(tuple_item):\n","            if index != (len(tuple_item)-1):\n","                tuple_str += element + '|'\n","            else:\n","                tuple_str += element\n","        ngrams_str.append(tuple_str)\n","    return ngrams_str\n","\n","#function to calculate Jensen-Shannon distance\n","def kl_divergence(p, q):\n","    eps = 0.00000001\n","    return np.sum(np.where(p < eps, 0, np.where(q < eps,0, p * np.log(p / (1.0*q)))))\n","\n","def jensen_shannon_distance(p, q):\n","    m = 0.5 * (p + q)\n","    return 0.5 * (kl_divergence(p, m) + kl_divergence(q, m))"]},{"cell_type":"code","execution_count":null,"id":"aac5d703","metadata":{"id":"aac5d703"},"outputs":[],"source":["#add columns to trace data containing arrays for probability data\n","traces['ProbDict'] = traces.apply(lambda row: calc_probabilities(row['NGrams'], all_ngrams_list, False), axis = 1)\n","traces['ProbArray'] = traces.apply(lambda row: calc_probabilities(row['NGrams'], all_ngrams_list, True), axis = 1)"]},{"cell_type":"code","execution_count":null,"id":"ba9b0aaa","metadata":{"id":"ba9b0aaa"},"outputs":[],"source":["example_dict = traces['ProbDict'].iloc[0]\n","example_array = traces['ProbArray'].iloc[0]\n","#check translation functions work\n","example_dict_converted_to_array = prob_dict_to_array(example_dict)\n","example_array_converted_to_dict = prob_array_to_dict(example_array, all_ngrams_list)\n","\n","print(np.array_equal(example_dict_converted_to_array, example_array))\n","print(example_array_converted_to_dict == example_dict)\n","\n","#check probability array is normalised\n","print(sum(example_array))"]},{"cell_type":"code","execution_count":null,"id":"baf6b8d0","metadata":{"id":"baf6b8d0"},"outputs":[],"source":["#calculate distance matrix for all pairwise trace combinations\n","def symm_distance_matrix(df, distance_func, colname):\n","    traces = df[colname].tolist()\n","    index_combinations = list(combinations(range(len(traces)), 2))\n","\n","    distance_values = [distance_func(traces[i],traces[j]) for i, j in index_combinations]\n","\n","    num_rows = len(df)\n","    distance_matrix = pd.DataFrame(index=range(num_rows), columns=range(num_rows))\n","\n","    for (i, j), distance_value in zip(index_combinations, distance_values):\n","        distance_matrix.at[i, j] = distance_value\n","        distance_matrix.at[j, i] = distance_value  # mirror the value\n","\n","    return distance_matrix.fillna(0)  # fill NaN values with zeros for diagonal elements\n","\n","js_dist_matrix = symm_distance_matrix(traces, jensen_shannon_distance, 'ProbArray')"]},{"cell_type":"code","execution_count":null,"id":"847fef7f","metadata":{"id":"847fef7f"},"outputs":[],"source":["#now that we have the distance matrix we can perform K-means clustering. We start by looking at\n","#inertia and elbow method\n","#inertia and elbow method\n","range_n_clusters = range(1, 5, 1)\n","inertia_vals = []\n","for num_clusters in range_n_clusters:\n","    # Initialize the clusterer with n_clusters value and a random generator\n","    # seed of 10 for reproducibility.\n","    clusterer = KMeans(n_clusters=num_clusters)\n","\n","    # Fit the model to the data\n","    clusterer.fit(js_dist_matrix)\n","\n","    #clusterer = KMeans(n_clusters=n_clusters, init='k-means++', n_init= 'warn', max_iter=300, tol=0.0001,\n","    #                verbose=0, random_state= 10, copy_x=True, algorithm='lloyd')\n","\n","    #cluster_labels = clusterer.fit_predict(trace_X)\n","    inertia_vals.append(clusterer.inertia_)\n","\n","#scale the inertia vals so that the first value is one\n","inertia_vals = np.array(inertia_vals)/inertia_vals[0]\n","\n","#plot as a line plot\n","plt.plot(range_n_clusters, inertia_vals)\n","plt.xticks(range_n_clusters)\n","plt.xlabel(\"Number of clusters\")\n","plt.ylabel(\"Scaled inertia\")\n","\n","#output inertia values\n","print(inertia_vals)"]},{"cell_type":"code","execution_count":null,"id":"bcefc55e","metadata":{"id":"bcefc55e"},"outputs":[],"source":["#silhouette analysis\n","range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n","silhouette_avg_list = []\n","\n","for n_clusters in range_n_clusters:\n","    # Create a subplot with 1 row and 1 columns\n","    fig, ax1 = plt.subplots(1,1)\n","    fig.set_size_inches(7, 3.5)\n","\n","    # The 1st subplot is the silhouette plot\n","    # The silhouette coefficient can range from -1, 1\n","    ax1.set_xlim([-0.1, 1])\n","    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n","    # plots of individual clusters, to demarcate them clearly.\n","    ax1.set_ylim([0, len(js_dist_matrix) + (n_clusters + 1) * 10])\n","\n","    # Initialize the clusterer with n_clusters value and a random generator\n","    # seed of 10 for reproducibility.\n","    clusterer = KMeans(n_clusters=n_clusters)\n","    clusterer.fit(js_dist_matrix)\n","\n","    # The silhouette_score gives the average value for all the samples.\n","    # This gives a perspective into the density and separation of the formed\n","    # clusters\n","    silhouette_avg = silhouette_score(js_dist_matrix, clusterer.labels_, metric = 'precomputed')\n","    silhouette_avg_list.append(silhouette_avg)\n","    print(\n","        \"For n_clusters =\",\n","        n_clusters,\n","        \"The average silhouette_score is :\",\n","        silhouette_avg,\n","    )\n","\n","    # Compute the silhouette scores for each sample\n","    sample_silhouette_values = silhouette_samples(js_dist_matrix, clusterer.labels_, metric = 'precomputed')\n","\n","    y_lower = 10\n","    for i in range(n_clusters):\n","        # Aggregate the silhouette scores for samples belonging to\n","        # cluster i, and sort them\n","        ith_cluster_silhouette_values = sample_silhouette_values[clusterer.labels_ == i]\n","\n","        ith_cluster_silhouette_values.sort()\n","\n","        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n","        y_upper = y_lower + size_cluster_i\n","\n","        color = cm.nipy_spectral(float(i) / n_clusters)\n","        ax1.fill_betweenx(\n","            np.arange(y_lower, y_upper),\n","            0,\n","            ith_cluster_silhouette_values,\n","            facecolor=color,\n","            edgecolor=color,\n","            alpha=0.7,\n","        )\n","\n","        # Label the silhouette plots with their cluster numbers at the middle\n","        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n","\n","        # Compute the new y_lower for next plot\n","        y_lower = y_upper + 10  # 10 for the 0 samples\n","\n","    #ax1.set_title(\"The silhouette plot for the various clusters.\")\n","    ax1.set_xlabel(\"The silhouette coefficient values\")\n","    ax1.set_ylabel(\"Cluster label\")\n","\n","    # The vertical line for average silhouette score of all the values\n","    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n","\n","    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n","    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n","\n","    plt.suptitle(\n","        #\"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n","        \"Number of clusters = %d\"\n","        % n_clusters,\n","        fontsize=14,\n","        fontweight=\"bold\",\n","    )\n","\n","plt.show()\n","\n","#also we plot just the average silhouette values by cluster number\n","plt.plot(range_n_clusters, silhouette_avg_list)\n","plt.xlabel(\"Number of clusters\")\n","plt.ylabel(\"Silhouette Average\")"]},{"cell_type":"code","execution_count":null,"id":"3d3dd683","metadata":{"id":"3d3dd683"},"outputs":[],"source":["#examine centroids for two clusters\n","num_clusters = 2\n","clusterer = KMeans(n_clusters=num_clusters)\n","\n","# Fit the model to the data\n","clusterer.fit(js_dist_matrix)\n","\n","#add cluster label to traces\n","traces['ClusterLabel'] = clusterer.labels_\n","\n","#split data by cluster label\n","X_0 =traces[traces['ClusterLabel'] == 0]['ProbArray']\n","X_1 =traces[traces['ClusterLabel'] == 1]['ProbArray']\n","\n","#next we can compute the average probability array for each cluster\n","average_prob_arr_cluster0 = np.mean(X_0, axis = 0)\n","average_prob_arr_cluster1 = np.mean(X_1, axis = 0)\n","\n","#and convert them into dictionaries\n","average_prob_dict_cluster0 = prob_array_to_dict(average_prob_arr_cluster0, all_ngrams_list)\n","average_prob_dict_cluster1 = prob_array_to_dict(average_prob_arr_cluster1, all_ngrams_list)\n","\n","#finally check they are still normalised\n","print(np.sum(average_prob_arr_cluster0))\n","print(np.sum(average_prob_arr_cluster1))"]},{"cell_type":"code","execution_count":null,"id":"2f5f327d","metadata":{"id":"2f5f327d"},"outputs":[],"source":["#check which agents we have in which cluster\n","Agents_0 = traces[traces['ClusterLabel'] == 0]['AgentName']\n","Agents_1 = traces[traces['ClusterLabel'] == 1]['AgentName']\n","\n","# Use Counter to count frequencies\n","frequency_count_0 = Counter(Agents_0)\n","frequency_count_1 = Counter(Agents_1)\n","\n","# Print the frequency count\n","for value, count in frequency_count_0.items():\n","    print(f\"{value}: {count} times\")\n","\n","for value, count in frequency_count_1.items():\n","    print(f\"{value}: {count} times\")"]},{"cell_type":"code","execution_count":null,"id":"5b125e94","metadata":{"id":"5b125e94"},"outputs":[],"source":["#function to plot two distributions side by side\n","def plot_distriution_comparison(distribution_dict_1, distribution_dict_2, label1 = '', label2 = '', threshold = 0):\n","    #find a common domain where all probbaility values are greater than a given threshold\n","    common_ngrams = return_common_ngrams_above_threshold(distribution_dict_1, distribution_dict_2, threshold)\n","\n","    #extract probability arrays for these common n-grams\n","    distribution_dict_1_reduced = {key: distribution_dict_1[key] for key in common_ngrams}\n","    distribution_dict_2_reduced = {key: distribution_dict_2[key] for key in common_ngrams}\n","    distribution_array_1_reduced = prob_dict_to_array(distribution_dict_1_reduced)\n","    distribution_array_2_reduced = prob_dict_to_array(distribution_dict_2_reduced)\n","\n","    #next plot probability distributions\n","\n","    #need to convert common_ngrams into a list of strings as opposed to tuples containing strings\n","    common_ngrams_str = convert_ngram_tuples_to_strings(common_ngrams)\n","\n","    #plot discrete probability distributions side by side\n","\n","    # Set the width of the bars\n","    bar_width = 0.35\n","\n","    # Calculate the x-coordinates for the bars\n","    x_values1 = np.arange(len(common_ngrams_str))\n","    x_values2 = x_values1 + bar_width\n","\n","    plt.bar(x_values1, distribution_array_1_reduced, width=bar_width, label = label1)\n","    plt.bar(x_values2, distribution_array_2_reduced, width=bar_width, label = label2)\n","\n","    plt.xticks(x_values1 + bar_width / 2, common_ngrams_str)\n","    plt.xticks(rotation=90)\n","    plt.ylim(threshold)\n","    plt.legend()\n","    plt.show()\n","\n","plot_distriution_comparison(average_prob_dict_cluster0, average_prob_dict_cluster1, 'Cluster 0', 'Cluster 1', 0.01)"]},{"cell_type":"code","execution_count":null,"id":"aa04f866","metadata":{"id":"aa04f866"},"outputs":[],"source":["#plot example probability distribution for a given play trace for illustration purposes\n","prob_dict = traces['ProbDict'].iloc[0]\n","prob_dict_nonzero = {gram: value for gram, value in prob_dict.items() if value > 0}\n","xvals = convert_ngram_tuples_to_strings(prob_dict_nonzero.keys())\n","yvals = prob_dict_nonzero.values()\n","plt.bar(xvals, yvals, label = 'DW strategy')\n","plt.xticks(rotation=90)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"d3fdf13f","metadata":{"id":"d3fdf13f"},"outputs":[],"source":["#also compute centroid using weighted average as opposed to direct average\n","def calculate_centroid(vectors, dist_func, max_iterations=100, tolerance=1e-6):\n","    #Iteratively update centroid\n","    centroid = np.mean(vectors, axis=0)\n","\n","    for _ in range(max_iterations):\n","        # Step 2: Calculate distance to centorid\n","        distances = np.array([dist_func(centroid, vec) for vec in vectors])\n","\n","        # Step 3: Weighted sum based on inverse distances\n","        weights = 1 / (distances + 1e-9)  # Small constant added to avoid division by zero\n","        #weighted_sum = np.sum(weights[:, np.newaxis] * vectors, axis=0)\n","        weighted_sum = np.sum(weights * vectors, axis=0)\n","\n","        # Step 4: Normalize the result\n","        new_centroid = weighted_sum / np.sum(weights)\n","\n","        # Check convergence\n","        if np.linalg.norm(new_centroid - centroid) < tolerance:\n","            break\n","\n","        centroid = new_centroid\n","\n","    return centroid"]},{"cell_type":"code","execution_count":null,"id":"c0df0bd0","metadata":{"id":"c0df0bd0"},"outputs":[],"source":["#recompute cluster 0 centroid using weighted averages and compare to direct average\n","X_0 =traces[traces['ClusterLabel'] == 0]['ProbArray']\n","\n","weighted_avg_centroid = calculate_centroid(X_0, jensen_shannon_distance)\n","straight_avg_centroid = np.mean(X_0, axis = 0)\n","\n","#plot side by side\n","weighted_avg_centroid_dict = prob_array_to_dict(weighted_avg_centroid, all_ngrams_list)\n","straight_avg_centroid_dict = prob_array_to_dict(straight_avg_centroid, all_ngrams_list)\n","plot_distriution_comparison(weighted_avg_centroid_dict, straight_avg_centroid_dict, 'Weighted average', 'Average',0.01)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"3s5ncoGtDaU3"},"id":"3s5ncoGtDaU3","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}